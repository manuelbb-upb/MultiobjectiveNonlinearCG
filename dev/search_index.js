var documenterSearchIndex = {"docs":
[{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"EditURL = \"https://github.com/manuelbb-upb/MultiobjectiveNonlinearCG/blob/main/docs/src/literate_jl/two_rosenbrock.jl\"","category":"page"},{"location":"generated/two_rosenbrock/#Two-Rosenbrock-Functions","page":"2 Rosenbrocks","title":"Two Rosenbrock Functions","text":"","category":"section"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"In single-objective optimization, the Rosenbrock function is a prominent example of an objective function that is hard for vanilla steepest descent. It has a flat valley around its global optimum, so the gradients become small.","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"In this example, we are going to look at a bi-objective problem constructed from parameterized Rosenbrock functions. The Rosenbrock function","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"f_ab(x_1 x_2) = b( x_2 - x_1^2 )^2 + (a - x_1)^2","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"has its global minimum at (a a^2) with f(a a^2) = 0. Its gradient is","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"nabla f_a(symbfx) =\n    beginbmatrix\n        -4b(x_2 - x_1^2)x_1 - 2(a-x_1) \n        2b(x_2 - x_1^2)\n    endbmatrix\n=\n    beginbmatrix\n        4bx_1^3 -4b x_1 x_2 + 2x_1 - 2a\n        \n        -2b x_1^2 + 2b x_2\n    endbmatrix","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Let's plot the Rosenbrock function's contours to see the valley. We use CairoMakie for plotting.","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"using CairoMakie\nusing Printf","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Moreover, there are some custom definitions in an external file:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"include(joinpath(joinpath(\"..\", \"literate_jl\"), \"makie_theme.jl\"))\nnothing #hide\n\n# Define the function:\nf(x1, x2, a, b) = b * (x2 - x1^2)^2 + (a - x1)^2","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"I also want to show the drawbacks of using Standard Gradient Descent, so let's do an optimization run. The gradient of the Rosenbrock function is known analitically (see above):","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"df(x1, x2, a, b) = [\n    -4*b*(x2-x1^2)*x1 - 2*(a-x1),\n    2*b*(x2-x1^2)\n]","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"For (multi-objective) optimization, we use our package:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"import MultiobjectiveNonlinearCG as M","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Setup objective for single objective optimization:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"objf_so = x -> [f(x[1], x[2], 1.0, 100),]\njacT_so = x -> reshape(df(x[1], x[2], 1.0, 100), :, 1)\n\n# cache for gathering iteration data:\ncache_so = M.GatheringCallbackCache(Float64)\ncallbacks_so = [M.GatheringCallback(cache_so),]\n\ndescent_rule_so = M.SteepestDescentRule(M.StandardArmijoRule())\n_ = M.optimize([-1.8, 0.0], objf_so, jacT_so;\n    descent_rule=descent_rule_so, max_iter=100, callbacks=callbacks_so)","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Let's proceed to plotting:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"# I am using a `let` block here to not pollute the global scope ...\nlet\n    set_theme!(DOC_THEME2) #hide\n    # evaluation range\n    X1 = LinRange(-2, 2, 100)\n    X2 = X1\n    # define function for ``a=1, b=100``\n    F = (x1, x2) -> f(x1, x2, 1, 100)\n\n    # initialize figure\n    fig = Figure(;)\n\n    # set global title\n    Label(fig[1, 1:4], \"Rosenbrock Function.\"; fontsize=60f0)\n\n    # plot filled contours in left axis\n    ax1 = Axis(fig[2,2]; aspect=1, title=L\"f(x_1, x_2)\", ylabelvisible=false)\n    c = contourf!(ax1, X1, X2, F)\n    scatter!(ax1, (1, 1); color=DOC_COLORS[:min])\n    # and also give it a colorbar\n    Colorbar(fig[2,1], c;\n        flipaxis=false, ticks=[0, 1e3, 2e3, 3e3],\n        tickformat=nums->[@sprintf(\"%dK\",n/1000) for n in nums]\n    )\n\n    # plot log contours in right axis\n    ax2 = Axis(fig[2,3], aspect=1, title=L\"\\log(f(x_1, x_2)))\")\n    c = contourf!(ax2, X1, X2, log10 ∘ F)\n    scatter!(ax2, (1, 1); color=DOC_COLORS[:min])\n    Colorbar(fig[2,4], c;\n        ticks=[-2, -1, 0, 1, 2, 3],\n    )\n\n    # plot iterates\n    x_it = Tuple.(cache_so.x_arr)\n    xlims!(ax1, (-2,2))\n    ylims!(ax1, (-2,2))\n    xlims!(ax2, (-2,2))\n    ylims!(ax2, (-2,2))\n    scatterlines!(ax1, x_it; markersize=15f0,color=DOC_COLORS[:sd])\n    scatterlines!(ax2, x_it; markersize=15f0,color=DOC_COLORS[:sd])\n\n    linkaxes!(ax1, ax2)\n\n    # make colorbars have nice size\n    rowsize!(fig.layout, 2, Aspect(2,1))\n\n    # display plot\n    fig\nend","category":"page"},{"location":"generated/two_rosenbrock/#Bi-Objective-Problem","page":"2 Rosenbrocks","title":"Bi-Objective Problem","text":"","category":"section"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Now let a_1 a_2 in ℝ and b_1  0 b_2  0, define f_1 = f_a_1 b_1 and f_2 = f_a_2 b_2, and consider","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"min_symbfxin ℝ^2\n    beginbmatrix\n        f_1(symbf x)\n        \n        f_2(symbf x)\n    endbmatrix","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"The KKT conditions read","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"α\n    beginbmatrix\n        4b_1x_1^3 - 4b_1 x_1 x_2 + 2x_1 - 2a_1\n        \n        -2b_1 x_1^2 + 2b_1 x_2\n    endbmatrix\n+ (1-α)\n    beginbmatrix\n        4b_2x_1^3 - 4b_2 x_1 x_2 + 2x_1 - 2a_2\n        \n        -2b_2 x_1^2 + 2b_2 x_2\n    endbmatrix\n=0 qquad αin 01","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"The second equation gives","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"beginaligned\n-2(αb_1 + (1-α)b_2)x_1^2 + 2(αb_1 + (1-α)b_2)x_2 = 0 \n quad x_2 = x_1^2\nendaligned","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"With this, the terms 4b_1x_1^3 - 4b_1 x_1 x_2 and 4b_2x_1^3 - 4b_2 x_1 x_2 cancel out and the first equation becomes:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"beginaligned\n0 = 2x_1 - 2αa_1 -2(1-α)a_2\n  x_1 = ( αa_1 + (1-α) a_2)\nendaligned","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Thus, the Pareto-critical set is a parabolic segment with x_1 ranging from a_1 to a_2 and x_2 = x_1^2.","category":"page"},{"location":"generated/two_rosenbrock/#Plotting-the-Pareto-Set","page":"2 Rosenbrocks","title":"Plotting the Pareto-Set","text":"","category":"section"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Let's fix some parameters and define our objectives:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"a1 = 1.0\na2 = 2.0\nb1 = b2 = 100\nf1(x1, x2) = f(x1, x2, a1, b1)\nf2(x1, x2) = f(x1, x2, a2, b2)","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Again, I do the plotting in a let block, because I might want to use other ranges later on:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"let\n    set_theme!(DOC_THEME2) #hide\n\n    # evaluation range\n    X1 = LinRange(-4.1, 4.1, 100)\n    X2 = X1\n\n    # initialize figure\n    fig = Figure(;)\n    ax1 = Axis(fig[2,2]; aspect=1, title=L\"f_1(x_1, x_2)\", ylabelvisible=false)\n    ax2 = Axis(fig[2,3], aspect=1, title=L\"f_2(x_1, x_2)\")\n\n    linkaxes!(ax1, ax2)\n\n    # set global title\n    Label(fig[1, 1:4], \"2 Rosenbrock Functions.\"; fontsize=60f0)\n\n    # plot filled contours in left axis\n    c = contourf!(ax1, X1, X2, f1)\n    # and also give it a colorbar\n    Colorbar(fig[2,1], c;\n        flipaxis=false,\n        tickformat=nums->[@sprintf(\"%.1fK\",n/1000) for n in nums]\n    )\n\n    # plot log contours in right axis\n    c = contourf!(ax2, X1, X2, f2)\n    Colorbar(fig[2,4], c;\n            tickformat=nums->[@sprintf(\"%.1fK\",n/1000) for n in nums]\n    )\n\n    # plot Pareto set into both axes\n    A = LinRange(a1, a2, 100)\n    lines!(ax1, A, A.^2; color=DOC_COLORS[:PS], label=\"PS\")\n    lines!(ax2, A, A.^2; color=DOC_COLORS[:PS], label=\"PS\")\n\n    # plot minima\n    scatter!(ax1, (a1, a1^2); color=DOC_COLORS[:min])\n    scatter!(ax2, (a2, a2^2); color=DOC_COLORS[:min])\n\n    # make colorbars have nice size\n    rowsize!(fig.layout, 2, Aspect(2,1))\n\n    # display plot\n    fig\nend","category":"page"},{"location":"generated/two_rosenbrock/#Optimization","page":"2 Rosenbrocks","title":"Optimization","text":"","category":"section"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"# define gradients:\ndf1(x1, x2) = df(x1, x2, a1, b1)\ndf2(x1, x2) = df(x1, x2, a2, b2)","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"We need a vector-vector objective and a vector-matrix transposed jacobian:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"objf(x) = [f1(x[1], x[2]), f2(x[1], x[2])]\njacT(x) = hcat(df1(x[1], x[2]), df2(x[1], x[2]))","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Reproducibly initialize starting site:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"import Random\nRandom.seed!(2178)\nx0 = -4 .+ 8 .+ rand(2)","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Setup an optimization run to gather information in cache","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"function do_experiment(x0; descent_rule, max_iter=100)\n    cache = M.GatheringCallbackCache(Float64)\n    callbacks = vcat(M.DEFAULT_CALLBACKS, M.GatheringCallback(cache))\n    _ = M.optimize(x0, objf, jacT; descent_rule, max_iter, callbacks)\n    return cache\nend","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Compare Steepest Descent and some CG directions. To make repeated tasks easier, I set up a list of experiments to do:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"experiment_settings = [\n    (\"SD\", M.SteepestDescentRule(M.StandardArmijoRule()), :sd,),\n    (\"SDm \", M.SteepestDescentRule(M.ModifiedArmijoRule()), :sdM,),\n    (\"PRP3\", M.PRP(M.ModifiedArmijoRule(), :sd), :prp3,),\n    (\"PRP2\", M.PRPGradProjection(M.ModifiedArmijoRule(), :sd), :prpOrth,),\n    (\"FR\", M.FRRestart(M.ModifiedArmijoRule(), :sd), :frRestart,),\n];\nnothing #hide","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"In single-objective optimization, some people try to improve the convergence speed by minimizing a quadratic model along the CG direction.","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"push!(experiment_settings,  (\"SDsz \", M.SteepestDescentRule(M.StandardArmijoRule(;σ_init=M.QuadApprox())), :sdSZ,))\npush!(experiment_settings,  (\"PRP3sz \", M.PRP(M.ModifiedArmijoRule(;σ_init=M.QuadApprox()), :sd), :prp3SZ,))\n\nexperiment_results = []\nfor (_, descent_rule, _) in experiment_settings\n    cache = do_experiment(x0; descent_rule)\n    # Stacking iteration sites into matrices makes calculation\n    # of axis bounds easier:\n    X = reduce(hcat, cache.x_arr)\n    push!(experiment_results, X)\nend","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"After the experiments have run, I need a helper function to determine the plotting limits:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"function get_lims(Xs...; margin=0.1)\n    xlims = [Inf, -Inf]\n    ylims = [Inf, -Inf]\n\n    for X in Xs\n        _xlims, _ylims = extrema(X, dims=2)\n        xlims[1] = min(xlims[1], _xlims[1])\n        xlims[2] = max(xlims[2], _xlims[2])\n        ylims[1] = min(ylims[1], _ylims[1])\n        ylims[2] = max(ylims[2], _ylims[2])\n    end\n\n    if margin > 0\n        xw = xlims[2] - xlims[1]\n        xlims[1] -= margin * xw\n        xlims[2] += margin * xw\n\n        yw = ylims[2] - ylims[1]\n        ylims[1] -= margin * yw\n        ylims[2] += margin * yw\n    end\n\n    return Tuple(xlims), Tuple(ylims)\nend","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Finally, the plotting is done much the same as before. First, plot all trajectories into a decision space plot:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"(x1_min, x1_max), (x2_min, x2_max) = get_lims(experiment_results...)\nlet\n    set_theme!(DOC_THEME2) #hide\n    # evaluation range\n    X1 = LinRange(x1_min, x1_max, 100)\n    X2 = LinRange(x2_min, x2_max, 100)\n    # initialize figure\n    fig = Figure(;)\n    ax1 = Axis(fig[2,2]; aspect=1, title=L\"f_1(x_1, x_2)\", ylabelvisible=false)\n    ax2 = Axis(fig[2,3], aspect=1, title=L\"f_2(x_1, x_2)\")\n\n    linkaxes!(ax1, ax2)\n\n    # set global title\n    Label(fig[1, 1:4], L\"2 Rosenbrock Functions ($a_1=1, a_2=2$).\"; fontsize=60f0)\n\n    # plot filled contours in left axis\n    c = contourf!(ax1, X1, X2, f1)\n    # and also give it a colorbar\n    Colorbar(fig[2,1], c;\n        flipaxis=false,\n        tickformat=nums->[@sprintf(\"%.1fK\",n/1000) for n in nums]\n    )\n\n    # plot log contours in right axis\n    c = contourf!(ax2, X1, X2, f2)\n    Colorbar(fig[2,4], c;\n            tickformat=nums->[@sprintf(\"%.1fK\",n/1000) for n in nums]\n    )\n\n    # plot Pareto set into both axes\n    A = LinRange(a1, a2, 100)\n    lines!(ax1, A, A.^2; color=DOC_COLORS[:PS], label=\"PS\")\n    lines!(ax2, A, A.^2; color=DOC_COLORS[:PS], label=\"PS\")\n\n    # make colorbars have nice size\n    rowsize!(fig.layout, 2, Aspect(2,1))\n\n    # trajectories of optimization\n    for (ci, settings) = enumerate(experiment_settings[1:5])\n        label, _, prop_key = settings\n        X = experiment_results[ci]\n        label *= \"($(size(X,2)))\"\n        scatterlines!(ax1, X;\n            markersize=10f0, label, color=DOC_COLORS[prop_key], linestyle=DOC_LSTYLES[prop_key])\n        scatterlines!(ax2, X;\n            markersize=10f0, label, color=DOC_COLORS[prop_key], linestyle=DOC_LSTYLES[prop_key])\n    end\n    # activate legend\n    axislegend(ax1; position=:lb)\n\n    # display plot\n    fig\nend","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"The plot looks a bit cluttered, so do individual plots, too","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"function experiment_single_plot(ind)\n    global x1_min, x1_max, x2_min, x2_max\n    global experiment_settings, experiment_results\n\n    set_theme!(DOC_THEME2) #hide\n    # evaluation range\n    X1 = LinRange(x1_min, x1_max, 100)\n    X2 = LinRange(x2_min, x2_max, 100)\n    # initialize figure\n    fig = Figure(;)\n    ax1 = Axis(fig[2,2]; aspect=1, title=L\"f_1(x_1, x_2)\", ylabelvisible=false)\n    ax2 = Axis(fig[2,3], aspect=1, title=L\"f_2(x_1, x_2)\")\n\n    linkaxes!(ax1, ax2)\n\n    # set global title\n    Label(fig[1, 1:4], L\"2 Rosenbrock Functions ($a_1=1, a_2=2$).\"; fontsize=60f0)\n\n    # plot filled contours in left axis\n    c = contourf!(ax1, X1, X2, f1)\n    # and also give it a colorbar\n    Colorbar(fig[2,1], c;\n        flipaxis=false,\n        tickformat=nums->[@sprintf(\"%.1fK\",n/1000) for n in nums]\n    )\n\n    # plot log contours in right axis\n    c = contourf!(ax2, X1, X2, f2)\n    Colorbar(fig[2,4], c;\n            tickformat=nums->[@sprintf(\"%.1fK\",n/1000) for n in nums]\n    )\n\n    # plot Pareto set into both axes\n    A = LinRange(a1, a2, 100)\n    lines!(ax1, A, A.^2; color=DOC_COLORS[:PS], label=\"PS\")\n    lines!(ax2, A, A.^2; color=DOC_COLORS[:PS], label=\"PS\")\n\n    # make colorbars have nice size\n    rowsize!(fig.layout, 2, Aspect(2,1))\n\n    # trajectories of optimization\n    for ci in ind\n        label, _, prop_key = experiment_settings[ci]\n        X = experiment_results[ci]\n        label *= \"($(size(X,2)))\"\n        scatterlines!(ax1, X;\n            markersize=10f0, label, color=DOC_COLORS[prop_key], linestyle=DOC_LSTYLES[prop_key])\n        scatterlines!(ax2, X;\n            markersize=10f0, label, color=DOC_COLORS[prop_key], linestyle=DOC_LSTYLES[prop_key])\n    end\n    # activate legend\n    axislegend(ax1; position=:lb)\n\n    # display plot\n    fig\nend\n\nexperiment_single_plot([1,])\nexperiment_single_plot([2,])\nexperiment_single_plot([3,])\nexperiment_single_plot([4,])\nexperiment_single_plot([5,])\nexperiment_single_plot([6,])\nexperiment_single_plot([7,])","category":"page"},{"location":"generated/two_rosenbrock/#Criticality-Plot","page":"2 Rosenbrocks","title":"Criticality Plot","text":"","category":"section"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"The behavior of steepest descent becomes more apparent, when looking at the criticality as defined by the norm of the steepest descent direction.","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"function crit_map(x1, x2)\n    δ = M.frank_wolfe_multidir_dual((df1(x1,x2), df2(x1,x2)))\n    return sqrt(sum(δ.^2))\nend","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"The plot reveals a near critical parabola:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"function experiment_crit_plot(ind)\n    global x1_min, x1_max, x2_min, x2_max\n    global experiment_settings, experiment_results\n\n    set_theme!(DOC_THEME) #hide\n    # evaluation range (more fine-grained here)\n    X1 = LinRange(x1_min, x1_max, 200)\n    X2 = LinRange(x2_min, x2_max, 200)\n\n    fig = Figure()\n    ax = Axis(fig[1,1]; title=L\"\\log(\\Vert\\mathbf{\\delta}\\Vert^2)\")\n\n    c = heatmap!(ax, X1, X2, log10 ∘ crit_map)\n    Colorbar(fig[1,2], c)\n\n    # plot Pareto set into both axes\n    A = LinRange(a1, a2, 100)\n    lines!(ax, A, A.^2; color=DOC_COLORS[:PS], label=\"PS\", linewidth=5f0)\n\n    # trajectories of optimization\n    for ci in ind\n        label, _, prop_key = experiment_settings[ci]\n        X = experiment_results[ci]\n        label *= \"($(size(X,2)))\"\n        # shadow for distinguishable lines\n        lines!(ax, X; color=:black, linewidth=8f0)\n        scatterlines!(ax, X;\n            markersize=18f0, label, color=DOC_COLORS[prop_key], linestyle=DOC_LSTYLES[prop_key],\n            strokecolor=:black, strokewidth=1f0\n        )\n    end\n\n    axislegend(ax)\n    fig\nend\nexperiment_crit_plot([1,])\nexperiment_crit_plot([2,])\nexperiment_crit_plot([3,])\nexperiment_crit_plot([4,])\nexperiment_crit_plot([5,])","category":"page"},{"location":"generated/two_rosenbrock/#Statistics","page":"2 Rosenbrocks","title":"Statistics","text":"","category":"section"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"using Statistics","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"The next experiment fixes a set of num_runs starting points and tests various methods against each other. We limit the number of iterations and stop only if we are completely critical.","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"num_runs = 100\nmax_iter = 20\nrand_x0 = () -> -50 .+ 100 .* rand(2)\nX0 = [ rand_x0() for i=1:num_runs ]","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"For now, we are only interested in the iteration sites. We extract them from cache and store them in X_it:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"function do_runs(descent_rule; max_iter=20)\n    X_it = Vector{Vector{Vector{Float64}}}()\n    for x0 in X0\n        cache = M.GatheringCallbackCache(Float64)\n        callbacks = [M.CriticalityStop(;eps_crit=-Inf), M.GatheringCallback(cache)]\n        _ = M.optimize(x0, objf, jacT; descent_rule, max_iter, callbacks)\n\n        x_arr = copy(cache.x_arr)\n        last_x = last(x_arr)\n        for _=length(x_arr)+1:max_iter\n            push!(x_arr, last_x)\n        end\n        push!(X_it, x_arr)\n    end\n    return X_it\nend","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Perform all the experiments with previous settings:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"experiment_results2 = [\n    do_runs(descent_rule) for (_, descent_rule, _) in experiment_settings\n];\nnothing #hide","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"For every run, we want to compute the criticality symbfδ at each point:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"crit_map(x) = crit_map(x[1], x[2])\nfunction crit_index(X_it)\n    crit_vals = crit_map.(X_it)\n    crit_vals ./= first(crit_vals) # “normalize” with respect to first value\n    return crit_vals\nend","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Finally, we do some statistics.","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"function consume_results(X_it)\n    C = mapreduce( crit_index, hcat, X_it)\n    μ = vec(mean(C; dims=2))\n    σ = vec(std(C; dims=2))\n    quart1 = quantile.(eachrow(C), 0.25)\n    quart2 = vec(median(C; dims=2))\n    quart3 = quantile.(eachrow(C), 0.75)\n    return μ, σ, quart1, quart2, quart3\nend","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"Run and plot:","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"function compare_crit_plot(ind)\n    global experiment_settings, experiment_results2\n\n    fig = Figure()\n    ax = Axis(fig[1,1];\n        yscale=log10, xlabel=L\"k\",\n        ylabel=L\"\\Vert\\delta(x^{(k)})\\Vert/\\Vert\\delta_0\\Vert\",\n        title=\"2 Rosenbrocks, $(num_runs) runs in [-50, 50]².\",\n        yminorticksvisible=true, yticks=LogTicks([0, -1, -2, -3, -4, -5, -6, -7]),\n        yminorticks=IntervalsBetween(10),\n        limits = (nothing, (5e-8, 1.2))\n    )\n    for ci in ind\n        X_it = experiment_results2[ci]\n        label, _, prop_key = experiment_settings[ci]\n\n        μ, σ, q1, q2, q3 = consume_results(X_it)\n        it = 0:length(μ)-1\n        lines!(ax, it, μ; label = \"μ \" * label, color=DOC_COLORS[prop_key])\n        lines!(ax, it, q2; label = \"median\", color=DOC_COLORS[prop_key], linestyle=:dash)\n        band!(ax, it, q1, q3; label = \"50 %\", color=(DOC_COLORS[prop_key], 0.2))\n    end\n    axislegend(ax; patchsize=(40f0, 20f0))\n\n    fig\nend\n\ncompare_crit_plot([1,3])\ncompare_crit_plot([1,4])\ncompare_crit_plot([1,5])","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"","category":"page"},{"location":"generated/two_rosenbrock/","page":"2 Rosenbrocks","title":"2 Rosenbrocks","text":"This page was generated using Literate.jl.","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"<p align=\"center\">   <a href=\"https://revealjs.com\">   <img src=\"https://hakim-static.s3.amazonaws.com/reveal-js/logo/v1/reveal-black-text-sticker.png\" alt=\"reveal.js\" width=\"500\">   </a>   <br><br>   <a href=\"https://github.com/hakimel/reveal.js/actions\"><img src=\"https://github.com/hakimel/reveal.js/workflows/tests/badge.svg\"></a>   <a href=\"https://slides.com/\"><img src=\"https://s3.amazonaws.com/static.slid.es/images/slides-github-banner-320x40.png?1\" alt=\"Slides\" width=\"160\" height=\"20\"></a> </p>","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"reveal.js is an open source HTML presentation framework. It enables anyone with a web browser to create beautiful presentations for free. Check out the live demo at revealjs.com.","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"The framework comes with a powerful feature set including nested slides, Markdown support, Auto-Animate, PDF export, speaker notes, LaTeX typesetting, syntax highlighted code and an extensive API.","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"Want to create reveal.js presentation in a graphical editor? Try https://slides.com. It's made by the same people behind reveal.js.","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"","category":"page"},{"location":"slides/README/#Sponsors","page":"-","title":"Sponsors","text":"","category":"section"},{"location":"slides/README/","page":"-","title":"-","text":"Hakim's open source work is supported by <a href=\"https://github.com/sponsors/hakimel\">GitHub sponsors</a>. Special thanks to: <div align=\"center\">   <table>     <td align=\"center\">       <a href=\"https://workos.com/?utmcampaign=githubrepo&utmmedium=referral&utmcontent=revealjs&utm_source=github\">         <div>           <img src=\"https://user-images.githubusercontent.com/629429/151508669-efb4c3b3-8fe3-45eb-8e47-e9510b5f0af1.svg\" width=\"290\" alt=\"WorkOS\">         </div>         <b>Your app, enterprise-ready.</b>         <div>           <sub>Start selling to enterprise customers with just a few lines of code. Add Single Sign-On (and more) in minutes instead of months.</sup>         </div>       </a>     </td>   </table> </div>","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"","category":"page"},{"location":"slides/README/#Getting-started","page":"-","title":"Getting started","text":"","category":"section"},{"location":"slides/README/","page":"-","title":"-","text":"🚀 Install reveal.js\n👀 View the demo presentation\n📖 Read the documentation\n🖌 Try the visual editor for reveal.js at Slides.com\n🎬 Watch the reveal.js video course (paid)","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"","category":"page"},{"location":"slides/README/","page":"-","title":"-","text":"<div align=\"center\">   MIT licensed | Copyright © 2011-2023 Hakim El Hattab, https://hakim.se </div>","category":"page"},{"location":"slides/css/theme/README/#Dependencies","page":"-","title":"Dependencies","text":"","category":"section"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"Themes are written using Sass to keep things modular and reduce the need for repeated selectors across files. Make sure that you have the reveal.js development environment installed before proceeding: https://revealjs.com/installation/#full-setup","category":"page"},{"location":"slides/css/theme/README/#Creating-a-Theme","page":"-","title":"Creating a Theme","text":"","category":"section"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"To create your own theme, start by duplicating a .scss file in /css/theme/source. It will be automatically compiled from Sass to CSS (see the gulpfile) when you run npm run build -- css-themes.","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"Each theme file does four things in the following order:","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"Include /css/theme/template/mixins.scss","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"Shared utility functions.","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"Include /css/theme/template/settings.scss","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"Declares a set of custom variables that the template file (step 4) expects. Can be overridden in step 3.","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"Override","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"This is where you override the default theme. Either by specifying variables (see settings.scss for reference) or by adding any selectors and styles you please.","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"Include /css/theme/template/theme.scss","category":"page"},{"location":"slides/css/theme/README/","page":"-","title":"-","text":"The template theme file which will generate final CSS output based on the currently defined variables.","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"EditURL = \"https://github.com/manuelbb-upb/MultiobjectiveNonlinearCG/blob/main/src/dir_rules/multidir_frank_wolfe.jl\"","category":"page"},{"location":"generated/multidir_frank_wolfe/#Custom-Frank-Wolfe-Solver...","page":"Frank-Wolfe Solver","title":"Custom Frank-Wolfe Solver...","text":"","category":"section"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"... to compute the multi-objective steepest descent direction cheaply. For unconstrained problems, the direction can be computed by projecting symbf0in ℝ^n onto the convex hull of the negative objective gradients. This can be done easily with JuMP and a suitable solver (e.g., COSMO).","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"In “Multi-Task Learning as Multi-Objective Optimization” by Sener & Koltun, the authors employ a variant of the Frank-Wolfe-type algorithms defined in “Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization” by Jaggi.","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"The objective for the projection problem is","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"F(symbfα)\n= frac12  sum_i=1^K αᵢ fᵢ _2^2\n= frac12  nabla symbff^T symbfα _2^2\n= frac12 symbf a^T nabla symbff nabla symbff^T symbf α","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"Hence,","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"nabla F(symbfα)\n= nabla symbff nabla symbff^T symbf α\n= symbf M symbf α","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"The algorithm starts with some initial symbfα = α_1  α_K^T and optimizes F within the standard simplex S = symbf α = α_1  α_k α_i ge 0 sum_i α_i = 1 This leads to the following procedure:","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"Compute seed s as the minimizer of langle symbf s nabla F(symbf α_k) rangle = langle symbf s symbf M symbf α_krangle in S. The minimum is attained in one of the corners, i.e., symbf s = symbf e_t, where t is the minimizing index for the entries of symbf M symbf α_k.\nCompute the exact stepsize γin01 that minimizes\nF((1-γ)symbf α_k + γ symbf s)\nSet symbf α_k+1 = (1-γ_k) α_k + γ_k symbf s.","category":"page"},{"location":"generated/multidir_frank_wolfe/#Finding-the-Stepsize","page":"Frank-Wolfe Solver","title":"Finding the Stepsize","text":"","category":"section"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"Let's discuss step 2. Luckily, we can indeed (easily) compute the minimizing stepsize. Suppose symbf v  ℝⁿ and symbf u  ℝⁿ are vectors and symbf M  ℝ^nn is a symmetric square matrix. What is the minimum of the following function?","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"σ(γ) = ( (1-γ) symbf v + γ symbf u )ᵀ symbf M ( (1-γ) symbf v + γ symbf u) qquad  (γ  01)","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"We have","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"σ(γ) beginalignedt\n\t=\n\t( (1-γ) symbf v + γ symbf u )ᵀsymbfM ( (1-γ) symbf v + γ symbfu)\n\t\t\n\t=\n\t(1-γ)² underbracesymbfvᵀsymbfM symbfv_a +\n\t  2γ(1-γ) underbracesymbfuᵀsymbfM symbfv_b +\n\t    γ² underbracesymbfuᵀsymbfM symbfu_c\n\t\t\n\t=\n\t(1 + γ² - 2γ)a + (2γ - 2γ²)b + γ² c\n\t\t\n\t=\n\t(a -2b + c) γ² + 2 (b-a) γ + a\nendaligned","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"The variables a b and c are scalar. The boundary values are","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"σ₀ = σ(0) = a textand σ₁ = σ(1) = c","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"If (a-2b+c)  0  a-b  b-c, then the parabola is convex and has its global minimum where the derivative is zero:","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"2(a - 2b + c) y^* + 2(b-a) stackrel= 0\n \n\tγ^* = frac-2(b-a)2(a -2 b + c)\n\t\t= fraca-b(a-b)+(c-b)","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"If a-b  b -c, the parabola is concave and this is a maximum. The extremal value is","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"σ_* = σ(γ^*)\n\t= frac(a - b)^2(a-b)+(c-b) - frac2(a-b)^2(a-b) + (c-b) + a\n\t= a - frac(a-b)^2(a-b) + (c-b)","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"\"\"\"\n\tmin_quad(a,b,c)\n\nGiven a quadratic function ``(a -2b + c) γ² + 2 (b-a) γ + a`` with ``γ ∈ [0,1]``, return\n`γ_opt` minimizing the function in that interval and its optimal value `σ_opt`.\n\"\"\"\nfunction min_quad(a,b,c)\n\ta_min_b = a-b\n\tb_min_c = b-c\n\tif a_min_b > b_min_c\n\t\t# the function is a convex parabola and has its global minimum at `γ`\n\t\tγ = a_min_b /(a_min_b - b_min_c)\n\t\tif 0 < γ < 1\n\t\t\t# if its in the interval, return it\n\t\t\tσ = a - a_min_b * γ\n\t\t\treturn γ, σ\n\t\tend\n\tend\n\t# the function is either a line or a concave parabola, the minimum is attained at the\n\t# boundaries\n\tif a <= c\n\t\treturn 0, a\n\telse\n\t\treturn 1, c\n\tend\nend","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"To use the above function in the Frank-Wolfe algorithm, we define a helper according to the definitions of ab and c:","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"function min_chull2(M, v, u)\n\tMv = M*v\n\ta = v'Mv\n\tb = u'Mv\n\tc = u'M*u\n\treturn min_quad(a,b,c)\nend","category":"page"},{"location":"generated/multidir_frank_wolfe/#Completed-Algorithm","page":"Frank-Wolfe Solver","title":"Completed Algorithm","text":"","category":"section"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"The stepsize computation is the most difficult part. Now, we only have to care about stopping and can complete the solver for our sub-problem:","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"import LinearAlgebra as LA","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"function frank_wolfe_multidir_dual(grads; max_iter=10_000, eps_abs=1e-6)\n\n\tnum_objfs = length(grads)\n\tT = Base.promote_type(Float32, mapreduce(eltype, promote_type, grads))\n\n\t# 1) Initialize ``α`` vector. There are smarter ways to do this...\n\tα = fill(T(1/num_objfs), num_objfs)\n\n\t# 2) Build symmetric matrix of gradient-gradient products\n\t# # `_M` will be a temporary, upper triangular matrix\n\t_M = zeros(T, num_objfs, num_objfs)\n\tfor (i,gi) = enumerate(grads)\n\t\tfor (j, gj) = enumerate(grads)\n\t\t\tj<i && continue\n\t\t\t_M[i,j] = gi'gj\n\t\tend\n\tend\n\t# # mirror `_M` to get the full symmetric matrix\n\tM = LA.Symmetric(_M, :U)\n\n\t# 3) Solver iteration\n\t_α = copy(α)    \t\t# to keep track of change\n\tu = zeros(T, num_objfs) # seed vector\n\tfor _=1:max_iter\n\t\tt = argmin( M*α )\n\t\tv = α\n\t\tfill!(u, 0)\n\t\tu[t] = one(T)\n\n\t\tγ, _ = min_chull2(M, v, u)\n\n\t\tα .*= (1-γ)\n\t\tα[t] += γ\n\n\t\tif sum( abs.( _α .- α ) ) <= eps_abs\n\t\t\tbreak\n\t\tend\n\t\t_α .= α\n\tend\n\n\t# return -sum(α .* grads) # somehow, broadcasting leads to type instability here,\n\t# see also https://discourse.julialang.org/t/type-stability-issues-when-broadcasting/92715\n\treturn mapreduce(*, +, α, grads)\nend","category":"page"},{"location":"generated/multidir_frank_wolfe/#Caching","page":"Frank-Wolfe Solver","title":"Caching","text":"","category":"section"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"Looking into frank_wolfe_multidir_dual, we see that in each execution there are allocations. As the function is called repeatedly in some outer loop, it might proof beneficial to pre-allocate these arrays and use a cached version of the algorithm:","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"struct FrankWolfeCache{T}\n\tα :: Vector{T}\n\t_α :: Vector{T}\n\t_M :: Matrix{T}\n\tu :: Vector{T}\n\tsol :: Vector{T}\nend","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"The initializer works just as in frank_wolfe_multidir_dual:","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"function init_frank_wolfe_cache(grads)\n\tnum_objfs = length(grads)\n\tT = Base.promote_type(Float32, mapreduce(eltype, promote_type, grads))\n\treturn init_frank_wolfe_cache(T, num_objfs)\nend\n\nfunction init_frank_wolfe_cache(T, num_vars, num_objfs)\n\t# 1) Initialize ``α`` vector. There are smarter ways to do this...\n\tα = fill(T(1/num_objfs), num_objfs)\n\t_α = copy(α)\n\n\t# 2) Build symmetric matrix of gradient-gradient products\n\t# # `_M` will be a temporary, upper triangular matrix\n\t_M = zeros(T, num_objfs, num_objfs)\n\n\t# seed vector\n\tu = zeros(T, num_objfs)\n\n\t# solution vector\n\tsol = zeros(T, num_vars)\n\treturn FrankWolfeCache(α, _α, _M, u, sol)\nend","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"Of course, the new method ends in \"!\" to show that it mutates the cache. Also, we return the negative solution here, to avoid unnecessary multiplications later on:","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"function frank_wolfe_multidir_dual!(fw_cache::FrankWolfeCache{T}, grads; max_iter=10_000, eps_abs=1e-6) where T\n\t# Unpack working arrays from cache:\n\tα = fw_cache.α\n\t_α = fw_cache._α\n\t_M = fw_cache._M\n\tu = fw_cache.u\n\tsol = fw_cache.sol\n\n\t# 2) Build symmetric matrix of gradient-gradient products\n\tfor (i,gi) = enumerate(grads)\n\t\tfor (j, gj) = enumerate(grads)\n\t\t\tj<i && continue\n\t\t\t_M[i,j] = gi'gj\n\t\tend\n\tend\n\t# # mirror `_M` to get the full symmetric matrix\n\tM = LA.Symmetric(_M, :U)\n\n\t# 3) Solver iteration\n\t_α .= α    \t\t\t\t# to keep track of change\n\tfor _=1:max_iter\n\t\tt = argmin( M*α )\n\t\tv = α\n\t\tfill!(u, 0)\n\t\tu[t] = one(T)\n\n\t\tγ, _ = min_chull2(M, v, u)\n\n\t\tα .*= (1-γ)\n\t\tα[t] += γ\n\n\t\tif sum( abs.( _α .- α ) ) <= eps_abs\n\t\t\tbreak\n\t\tend\n\t\t_α .= α\n\tend\n\n\tfill!(sol, zero(T))\n\tfor (αℓ, gℓ) in zip(α, grads)\n\t\tsol .-= αℓ .* gℓ\n\tend\n\n\treturn nothing\nend","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"","category":"page"},{"location":"generated/multidir_frank_wolfe/","page":"Frank-Wolfe Solver","title":"Frank-Wolfe Solver","text":"This page was generated using Literate.jl.","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"EditURL = \"https://github.com/manuelbb-upb/MultiobjectiveNonlinearCG/blob/main/docs/src/literate_jl/two_parabolas.jl\"","category":"page"},{"location":"generated/two_parabolas/#Two-Parabolas-Example","page":"2 Parabolas","title":"Two-Parabolas Example","text":"","category":"section"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"The two parabolas problem in 2D reads as","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"min_symbfx  ℝ^2\n beginbmatrix\n    f_1(symbfx)\n    \n    f_2(symbfx)\n endbmatrix\n =\n beginbmatrix\n (x₁ - 1)^2 + (x₂ - 1)^2\n \n (x₁ + 1)^2 + (x₂ + 1)^2\n endbmatrix\n ","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"The Pareto-Set is the line connecting the individual minima, i.e.,","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"mathcal P_S\n  =\n    left\n      symbfx  ℝ^2 x₁ = x₂ x₁  -1 1\n    right","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"It's easy to setup for MultiobjectiveNonlinearCG. At the lowest level, its optimize method requires a starting point, its image vector, a modifying objective functional and a functional setting the transposed jacobian. Let's define all that:","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"\"Evaluate the objectives at `x` and store result in `y`.\"\nfunction objf!(y, x)\n    y[1] = sum( (x .- 1).^2 )\n    y[2] = sum( (x .+ 1).^2 )\n    return nothing\nend\n\n\"Evaluate objective derivatives at `x` and store transposed jacobian in `DfxT`.\"\nfunction jacT!(DfxT, x)\n    DfxT[:, 1] = x .- 1\n    DfxT[:, 2] = x .+ 1\n    DfxT .*= 2\n    return nothing\nend\n\n# initialize starting values\nimport Random\nx0 = 10 .* [-π, 2*ℯ]\nfx0 = zeros(2)\nobjf!(fx0, x0)","category":"page"},{"location":"generated/two_parabolas/#Optimize-using-Steepest-Descent","page":"2 Parabolas","title":"Optimize using Steepest Descent","text":"","category":"section"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"import MultiobjectiveNonlinearCG as M","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"To use multi-objective steepest descent, we'll first have to decide on a stepsize procedure. We can use a fixed stepsize, standard Armijo or modified Armijo backtracking. For steepest descent, it's most sensible to use standard Armijo:","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"descent_rule = M.SteepestDescentRule(M.StandardArmijoRule())","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"We are nearly ready to go. A maximum number of iterations can be provided by the max_iter keyword argument.","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"max_iter = 100","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"There is also a set of default stopping criteria, which can be inspected by looking at M.DEFAULT_CALLBACKS. To have a fair comparison, we reset them. Additionally, we use a special gathering callback to later plot the iterates:","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"cache1 = M.GatheringCallbackCache(Float64)\ncallbacks = [\n  M.CriticalityStop(; eps_crit=1e-6),\n  M.GatheringCallback(cache1),\n]\n\nx_fin, fx_fin, stop_code, meta1 = M.optimize(\n  x0, objf!, jacT!;\n  objf_is_mutating=true,\n  jac_is_mutating=true,\n  fx0, max_iter, callbacks, descent_rule,\n)\nmeta1.num_iter[]","category":"page"},{"location":"generated/two_parabolas/#Optimize-with-Modified-PRP-Direction","page":"2 Parabolas","title":"Optimize with Modified PRP Direction","text":"","category":"section"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"First initialize the gathering callback for this trial:","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"cache2 = M.GatheringCallbackCache(Float64)\ncallbacks = [\n  M.CriticalityStop(; eps_crit=1e-6),\n  M.GatheringCallback(cache2),\n]","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"Now, test some non-linear conjugate gradient direction:","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"descent_rule = M.PRP(M.ModifiedArmijoRule(), :sd)\n#descent_rule = M.FRRestart(M.ModifiedArmijoRule(), :sd)\nx_fin, fx_fin, stop_code, meta2 = M.optimize(\n  x0, objf!, jacT!;\n  objf_is_mutating=true,\n  jac_is_mutating=true,\n  fx0, max_iter, callbacks, descent_rule,\n)\nmeta2.num_iter[]","category":"page"},{"location":"generated/two_parabolas/#Plotting-the-results","page":"2 Parabolas","title":"Plotting the results","text":"","category":"section"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"We use CairoMakie for plotting.","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"using CairoMakie\nusing Printf","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"Additionally, there is some custom definitions in an external file:","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"include(joinpath(joinpath(\"..\", \"literate_jl\"), \"makie_theme.jl\"))\nset_theme!(DOC_THEME)\n\n# the `let` block is optional and used just to avoid polluting the global scope\nlet\n  fig = Figure()\n  ax = Axis(fig[1,1]; aspect=1)\n\n  lines!(ax, [(-1,-1), (1,1)];\n    linewidth=10f0, label=\"PS\", color=DOC_COLORS[:PS], linestyle=DOC_LSTYLES[:PS])\n  scatterlines!(ax, Tuple.(cache1.x_arr);\n    label=\"sd ($(meta1.num_iter))\", color=DOC_COLORS[:sd], linestyle=DOC_LSTYLES[:sd])\n  scatterlines!(ax, Tuple.(cache2.x_arr);\n    label=\"prp ($(meta2.num_iter))\", color=DOC_COLORS[:prp3], linstyle=DOC_LSTYLES[:prp3])\n\n  axislegend(ax)\n\n  fig\nend","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"Both runs finish after two iterations :)","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"","category":"page"},{"location":"generated/two_parabolas/","page":"2 Parabolas","title":"2 Parabolas","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#MultiobjectiveNonlinearCG.jl","page":"Home","title":"MultiobjectiveNonlinearCG.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for MultiobjectiveNonlinearCG.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"This is a package meant primarily for academic and research purposes. For my own sanity, I have incorporated a few convenience functions, but don't expect anything particularly usable or stable.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Some of the theory behind this package, and results generated with it are meant to be presented at GAMM2023 in Dresden.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Link to GAMM slides (fullscreen).","category":"page"},{"location":"","page":"Home","title":"Home","text":"<iframe style=\"width: 100%; aspect-ratio: 16/9;\" src=\"./slides/index.html\" />","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"EditURL = \"https://github.com/manuelbb-upb/MultiobjectiveNonlinearCG/blob/main/docs/src/literate_jl/alice_bob_plot.jl\"","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"include(joinpath(joinpath(\"..\", \"literate_jl\"), \"makie_theme.jl\")) #hide\nnothing #hide","category":"page"},{"location":"generated/alice_bob_plot/#Pareto-Optimality","page":"Pareto Optimality","title":"Pareto-Optimality","text":"","category":"section"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Consider the formal optimization problem","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"min_symbfxin ℝ^N\nbeginbmatrix\n    f_1(symbfx)\n    \n    vdots\n    \n    f_K(symbfx)\nendbmatrix\ntagMOP","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"What are solutions of a problem with multiple objectives? Well, acceptable trade-offs between the objective function values. Formally, we use the concept of Pareto-optimality.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"A point symbfx^*in ℝ^N is called Pareto-optimal if there is no symbfxin ℝ^N","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"that is at least as good as symbfx^*, i.e., no symbfx with f_ℓ(symbfx)  f_ℓ(symbfx^*) for all ℓ=1K,\nand that is strictly better in at least one objective, i.e., no symbfx for which there is some ℓin1K with f_ℓ(symbfx)f_ℓ(symbfx^*).","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"The set of all optimal solutions is the Pareto-Set and its image is the Pareto-Front.","category":"page"},{"location":"generated/alice_bob_plot/#Example","page":"Pareto Optimality","title":"Example","text":"","category":"section"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Alice 👩 and Bob 👨 want to meet. Alice lives at (1 1) and Bob lives at (-1 -1). So the distance to Alice's home is","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"d_A(x_1 x_2) = sqrt(x_1-1)^2 + (x_2-1)^2","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"For Bob, it is","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"d_B(x_1 x_2) = sqrt(x_1+1)^2 + (x_2+1)^2","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Deciding on a meeting venue is the bi-objective optimization problem","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"min_symbfxin ℝ2\nbeginbmatrix\n    d_A(symbf x)\n    \n    d_B(symbf x)\nendbmatrix","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Let's visualize the situation:","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"using CairoMakie\nusing FileIO","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Define the distance functions:","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"dA(x1, x2) = sqrt((x1-1)^2 + (x2-1)^2)\ndB(x1, x2) = sqrt((x1+1)^2 + (x2+1)^2)","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"A function to give us a basic figure with Alice and Bob in it:","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"markerA = load(joinpath(joinpath(\"..\", \"literate_jl\"),\"woman.png\"))\nmarkerB = load(joinpath(joinpath(\"..\", \"literate_jl\"),\"man.png\"))\n\nfunction setup_fig()\n    global markerA, markerB\n    set_theme!(DOC_THEME2) #hide\n    fig = Figure()\n\n    # set a title\n    Label(fig[1,1:2], \"Alice and Bob Want to Meet.\")\n\n    # left axis - decision space, where Alice and Bob live\n    ax1 = Axis(fig[2,1]; aspect=1.0)\n    xlims!(ax1, (-1.5, 1.5))\n    ylims!(ax1, (-1.5, 1.5))\n\n    # set markers for Alice and Bob\n    scatter!(ax1, (1, 1); marker=markerA, markersize=30)\n    scatter!(ax1, (-1, -1); marker=markerB, markersize=30)\n\n    # right axis - objective space, distance values\n    ax2 = Axis(fig[2,2]; aspect=1.0, xlabel=L\"d_A\", ylabel=L\"d_B\")\n    xlims!(ax2, (-0.1, 3.5))\n    ylims!(ax2, (-0.1, 3.5))\n    return fig, ax1, ax2\nend\n\n# show the basic image:\nfig0 = first(setup_fig())\nfig0","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"To compare various meeting positions, we build a function testing for Pareto-optimality in a discrete set with value vectors Y.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"function check_optimal(Y)\n    _Y = empty(Y)               # array of processed value vectors\n    isoptimal = zeros(Bool, 0)  # flags\n    for fi in Y\n        fi_isoptim = true\n        for (j,fj) in enumerate(_Y)\n            if all(fj .<= fi) && any(fj .< fi)\n                # fj is better than fi\n                fi_isoptim = false\n                break\n            end\n            # test, if fi is better than fj\n            if isoptimal[j]\n                if all(fi .<= fj) && any( fi .< fj)\n                    isoptimal[j] = false\n                end\n            end\n        end\n        push!(_Y, fi)\n        isoptimal = vcat(isoptimal, fi_isoptim)\n    end\n    return isoptimal\nend","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Let's look at some meeting places. First, only consider Alices' home:","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"X = [(1.0, 1.0),]\nY = [(dA(x[1], x[2]), dB(x[1], x[2])) for x in X]","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Obviously, the point is optimal in our discrete sample:","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"isopt = check_optimal(Y)\nall(isopt) == true","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"With more points, it gets more complicated. We want to scatter the X and Y points and use different markers for optimal and non-optimal points.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"function scatterOpt!(axX, axY, X, Y, isopt; colors)\n    @assert length(X) == length(Y) == length(isopt)\n\n    # plot non-optimal points first\n    si = sortperm(isopt)\n\n    for i=si\n        color = colors[i]\n        marker, strokewidth, strokecolor = if isopt[i]\n            (:circle, 0.5, :black)\n        else\n            (:xcross, 1.5, :orange)\n        end\n\n        scatter!(axX, (X[i]...); color, marker, strokewidth, strokecolor)\n        scatter!(axY, (Y[i]...); color, marker, strokewidth, strokecolor)\n    end\n    nothing\nend","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Now, Alice's place should get a round marker.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"let\n    fig, ax1, ax2 = setup_fig()\n    scatterOpt!(ax1, ax2, X, Y, isopt; colors=Makie.wong_colors())\n    fig\nend","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Now we include Bob's home.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"X = [\n    (1.0, 1.0),\n    (-1.0, -1.0)\n]\nY = [(dA(x[1], x[2]), dB(x[1], x[2])) for x in X]","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Still, both points are Pareto-optimal in our sample set.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"isopt = check_optimal(Y)\nisopt == [true, true]","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"This is reflected in the plot. Note, that individual minima are by definition always Pareto-optimal, also in the non-discrete case.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"let\n    fig, ax1, ax2 = setup_fig()\n    scatterOpt!(ax1, ax2, X, Y, isopt; colors=Makie.wong_colors())\n    fig\nend","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"By adding a third point, we see that it is important to distinguish our discrete comparisons and the continuous case.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"X = [\n    (1.0, 1.0),\n    (-1.0, -1.0),\n    (-1.0, 1.0),\n]\nY = [(dA(x[1], x[2]), dB(x[1], x[2])) for x in X]\nlet\n    fig, ax1, ax2 = setup_fig()\n    scatterOpt!(ax1, ax2, X, Y, check_optimal(Y); colors=Makie.wong_colors())\n    fig\nend","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Surprisingly, (-1 1) is considered optimal, despite it being fare away from Alice and Bob. (00) would certainly be preferrable for both:","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"X = [\n    (1.0, 1.0),\n    (-1.0, -1.0),\n    (-1.0, 1.0),\n    (0.0, 0.0),\n]\nY = [(dA(x[1], x[2]), dB(x[1], x[2])) for x in X]\n\nfig, ax1, ax2 = setup_fig()\nscatterOpt!(ax1, ax2, X, Y, check_optimal(Y); colors=Makie.wong_colors())\nfig","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"That's it! With more samples we get a better sense for the optimal points of the continuous problem (MOP). Thus, let's use a pseudo-random sampling of decision space and see if we can identify the Pareto Set.","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"using HaltonSequences\nusing ColorSchemes\nnum_X = 200\nX = [Tuple( -1.4 .+ 2.8 .* p  ) for p in HaltonPoint(2; length=num_X)]\nY = [(dA(x[1], x[2]), dB(x[1], x[2])) for x in X]\nscatterOpt!(\n    ax1, ax2, X, Y, check_optimal(Y);\n    colors=[get(ColorSchemes.acton, (i-1)/(num_X-1)) for i=1:num_X]\n)\nfig","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"Ok, we got a rough sense for the Pareto Set. Indeed, we can analitically show that its the line from (-1 -1) to (11).","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"lines!(ax1, [(-1, -1), (1, 1)]; linewidth=5f0, color=:blue)\nPF = [(dA(x,x), dB(x, x)) for x=1:-0.1:-1]\nlines!(ax2, PF; linewidth=5f0, color=:blue)\nfig","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"","category":"page"},{"location":"generated/alice_bob_plot/","page":"Pareto Optimality","title":"Pareto Optimality","text":"This page was generated using Literate.jl.","category":"page"}]
}
